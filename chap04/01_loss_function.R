# ゼロから作るDeep Learingをなるべく元の本のコードに準拠しつつ、R実装する
# 4.2.1 (p88-) 損失関数


rm(list=ls())


# 誤差二乗和 ---------------------------------------------------------------
# y: prediction
# t: true label (train)
mean_squared_error <- function(y, t){
  return( 0.5 * sum( (y - t)^2))
}

t <- c(0, 0, 1, 0, 0, 0, 0, 0, 0, 0)

y <- c(0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0)
mean_squared_error(y,t) # -> 0.0975

y <- c(0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0)
mean_squared_error(y,t) # -> 0.5975


# 交差エントロピー誤差 --------------------------------------------------------------
cross_entropy_error <- function(y, t){
  delta <- 1e-6
  -sum(t* log(y + delta))
}

t <- c(0, 0, 1, 0, 0, 0, 0, 0, 0, 0)

y <- c(0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0)
cross_entropy_error(y,t) # -> 0.0975

y <- c(0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0)
cross_entropy_error(y,t) # -> 0.5975


# END ------------------------------------------------------------------------


